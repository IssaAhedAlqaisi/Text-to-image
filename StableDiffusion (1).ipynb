{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install diffusers transformers accelerate scipy safetensors gradio --quiet"
      ],
      "metadata": {
        "id": "MKbzh0Y52eTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "# Load the model from Hugging Face\n",
        "access_token = \"please put your token from Hugging face\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=access_token\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Define the image generation function\n",
        "def generate_image(prompt):\n",
        "    image = pipe(prompt).images[0]\n",
        "    return image\n",
        "\n",
        "# Create the Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=generate_image,\n",
        "    inputs=gr.Textbox(label=\"Enter a text prompt\"),\n",
        "    outputs=gr.Image(label=\"Generated Image\"),\n",
        "    title=\"Text-to-Image Generator ðŸŽ¨\",\n",
        "    description=\"Enter a description, and a Stable Diffusion model will generate an image for you.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "qXxyHmC8y5CG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}